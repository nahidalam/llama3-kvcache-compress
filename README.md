# llama3-kvcache-compress

## Install
- Create your conda or virtual environment
- Or alternatively use this docker https://gist.github.com/kimbochen/40671e5625f2488cb3d43209df49c841
```
pip install torch transformers nvcomp
```
